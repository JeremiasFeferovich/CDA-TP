# ZonaProp Scraper

Scraper automatizado para extraer datos de propiedades inmobiliarias de ZonaProp.com.ar, desarrollado para el proyecto de **PredicciÃ³n de Precios de Viviendas en Buenos Aires**.

## ğŸ“‹ DescripciÃ³n

Este proyecto forma parte del trabajo de **Ciencia de Datos Aplicada** para desarrollar un modelo de predicciÃ³n de precios de viviendas. El scraper extrae informaciÃ³n detallada de departamentos en venta en Buenos Aires desde ZonaProp.

## ğŸ¯ Objetivos

- Recopilar datos de al menos 5,000 propiedades en Buenos Aires
- Extraer caracterÃ­sticas relevantes para predicciÃ³n de precios
- Generar dataset limpio y estructurado para anÃ¡lisis posterior
- Cumplir con buenas prÃ¡cticas de web scraping Ã©tico

## ğŸ—ï¸ Arquitectura del Proyecto

```
zonaprop_scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py          # InicializaciÃ³n del paquete
â”‚   â”œâ”€â”€ scraper.py           # Clase principal del scraper
â”‚   â”œâ”€â”€ data_extractor.py    # Extractor de datos de propiedades
â”‚   â”œâ”€â”€ utils.py            # Utilidades y funciones helper
â”‚   â””â”€â”€ config.py           # Configuraciones del sistema
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Datos crudos extraÃ­dos
â”‚   â”œâ”€â”€ processed/          # Datos procesados y limpios
â”‚   â””â”€â”€ logs/               # Logs del proceso de scraping
â”œâ”€â”€ example_usage.py        # Ejemplo de uso del scraper
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â””â”€â”€ README.md              # Esta documentaciÃ³n
```

## ğŸ“Š Datos ExtraÃ­dos

### InformaciÃ³n BÃ¡sica
- **ID de propiedad**: Identificador Ãºnico
- **Precio**: Valor en USD o ARS
- **Expensas**: Gastos mensuales adicionales

### UbicaciÃ³n
- **DirecciÃ³n**: DirecciÃ³n especÃ­fica
- **Barrio**: Barrio de Buenos Aires
- **Zona**: Capital Federal, GBA Norte, etc.

### CaracterÃ­sticas FÃ­sicas
- **Superficie total**: Metros cuadrados
- **Ambientes**: NÃºmero de ambientes
- **Dormitorios**: NÃºmero de dormitorios
- **BaÃ±os**: NÃºmero de baÃ±os
- **Cocheras**: Espacios de estacionamiento

### CaracterÃ­sticas Adicionales
- **Amenities**: Pileta, gimnasio, SUM, etc.
- **Estado**: Nuevo, usado, en construcciÃ³n
- **OrientaciÃ³n**: Norte, sur, este, oeste
- **Piso**: NÃºmero de piso
- **Inmobiliaria**: Empresa responsable

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone <repository-url>
cd zonaprop_scraper
```

### 2. Crear entorno virtual (recomendado)
```bash
python -m venv venv
source venv/bin/activate  # En Linux/Mac
# o
venv\\Scripts\\activate   # En Windows
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Verificar instalaciÃ³n de Chrome
El scraper requiere Google Chrome instalado en el sistema. ChromeDriver se descarga automÃ¡ticamente.

## ğŸ“– Uso

### Uso BÃ¡sico

```python
from src.scraper import ZonaPropScraper

# Crear instancia del scraper
scraper = ZonaPropScraper(
    headless=True,    # Ejecutar sin mostrar navegador
    max_pages=10      # MÃ¡ximo 10 pÃ¡ginas
)

# Ejecutar scraping
properties = scraper.scrape(start_page=1)

# Guardar datos
scraper.save_data(filename="propiedades_ba", format="csv")

# Obtener estadÃ­sticas
stats = scraper.get_statistics()
print(f"Propiedades extraÃ­das: {stats['total_properties']}")

# Cerrar scraper
scraper.close()
```

### Ejemplo Completo

```bash
# Ejecutar ejemplo incluido
python example_usage.py
```

### LÃ­nea de Comandos

```bash
# Scraping bÃ¡sico
python -m src.scraper --pages 5 --headless

# Scraping avanzado
python -m src.scraper \\
    --pages 20 \\
    --start-page 1 \\
    --output "propiedades_caba" \\
    --format csv \\
    --headless
```

#### ParÃ¡metros disponibles:
- `--pages`: NÃºmero mÃ¡ximo de pÃ¡ginas (default: 10)
- `--start-page`: PÃ¡gina inicial (default: 1)
- `--headless`: Ejecutar sin mostrar navegador
- `--output`: Nombre del archivo de salida
- `--format`: Formato de salida (csv/json)

## âš™ï¸ ConfiguraciÃ³n

### Modificar configuraciones en `src/config.py`:

```python
# Delays entre requests
SCRAPER_CONFIG = {
    "delay_between_requests": (2, 5),  # 2-5 segundos
    "delay_between_pages": (5, 10),   # 5-10 segundos
    "max_retries": 3,
    "max_pages": 100,
    "max_properties_per_session": 1000
}

# ConfiguraciÃ³n de Selenium
SELENIUM_CONFIG = {
    "headless": True,
    "window_size": (1920, 1080),
    "implicit_wait": 10,
    "page_load_timeout": 30
}
```

## ğŸ” Manejo de Errores

El scraper incluye manejo robusto de errores:

- **Timeouts**: Reintentos automÃ¡ticos
- **Elementos faltantes**: Valores por defecto
- **Cloudflare**: ConfiguraciÃ³n anti-detecciÃ³n
- **Logging**: Registro detallado de errores

### Logs

Los logs se guardan automÃ¡ticamente en `data/logs/` con:
- Timestamp de cada operaciÃ³n
- Errores y excepciones
- EstadÃ­sticas de progreso
- InformaciÃ³n de debug

## ğŸ“ˆ Salida de Datos

### Formato CSV
```csv
property_id,price,currency,expenses,address,neighborhood,zone,total_surface,rooms,bathrooms,parking_spaces,amenities,property_status,scraping_date
56054832,265000,USD,180000,"Condarco al 3000","Villa del Parque","Capital Federal",95,4,2,1,"['BalcÃ³n']","Usado","2025-08-30T14:30:00"
```

### Formato JSON
```json
{
  "property_id": "56054832",
  "price": 265000,
  "currency": "USD",
  "expenses": 180000,
  "address": "Condarco al 3000",
  "neighborhood": "Villa del Parque",
  "zone": "Capital Federal",
  "total_surface": 95,
  "rooms": 4,
  "bathrooms": 2,
  "parking_spaces": 1,
  "amenities": ["BalcÃ³n"],
  "property_status": "Usado",
  "scraping_date": "2025-08-30T14:30:00"
}
```

## ğŸ›¡ï¸ Consideraciones Ã‰ticas

### Buenas PrÃ¡cticas Implementadas:
- **Rate Limiting**: Delays entre requests para no sobrecargar el servidor
- **User-Agent Rotation**: RotaciÃ³n de navegadores para evitar detecciÃ³n
- **Respeto por robots.txt**: VerificaciÃ³n de polÃ­ticas del sitio
- **Uso AcadÃ©mico**: Datos utilizados solo para investigaciÃ³n

### LÃ­mites Implementados:
- MÃ¡ximo 1000 propiedades por sesiÃ³n
- Delays de 2-5 segundos entre requests
- Delays de 5-10 segundos entre pÃ¡ginas
- MÃ¡ximo 3 reintentos por pÃ¡gina

## ğŸ”§ Troubleshooting

### Problemas Comunes:

#### 1. Error de ChromeDriver
```bash
# SoluciÃ³n: Actualizar webdriver-manager
pip install --upgrade webdriver-manager
```

#### 2. Timeout en pÃ¡ginas
```python
# Aumentar timeout en config.py
SELENIUM_CONFIG["page_load_timeout"] = 60
```

#### 3. Cloudflare bloqueando requests
```python
# Usar modo no-headless y aumentar delays
scraper = ZonaPropScraper(headless=False)
SCRAPER_CONFIG["delay_between_requests"] = (5, 10)
```

#### 4. Elementos no encontrados
- Verificar que los selectores CSS en `config.py` estÃ©n actualizados
- ZonaProp puede cambiar su estructura HTML

## ğŸ“Š EstadÃ­sticas Esperadas

Para un scraping exitoso de 10 pÃ¡ginas (~200 propiedades):

- **Tiempo estimado**: 15-30 minutos
- **Datos vÃ¡lidos**: >95% de completitud
- **Errores esperados**: <5%
- **Barrios cubiertos**: 15-25 barrios de CABA

## ğŸ¤ ContribuciÃ³n

### Para contribuir al proyecto:

1. Fork del repositorio
2. Crear branch para feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit de cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push al branch (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“ Licencia

Este proyecto es para uso acadÃ©mico en el marco del curso de Ciencia de Datos Aplicada - ITBA.

## ğŸ‘¥ Autores

- **Ian Bernasconi** - Desarrollo y anÃ¡lisis
- **JeremÃ­as Feferovich** - Desarrollo y anÃ¡lisis

## ğŸ“ Contacto

Para consultas sobre el proyecto:
- Email: [contacto@proyecto.com]
- GitHub Issues: [link-to-issues]

## ğŸ”„ PrÃ³ximas Mejoras

- [ ] Scraping de casas y PHs
- [ ] IntegraciÃ³n con base de datos
- [ ] API REST para acceso a datos
- [ ] Dashboard de monitoreo
- [ ] Scraping incremental
- [ ] DetecciÃ³n automÃ¡tica de cambios en estructura HTML

---

**Nota**: Este scraper estÃ¡ diseÃ±ado especÃ­ficamente para ZonaProp.com.ar y puede requerir actualizaciones si el sitio cambia su estructura HTML.
