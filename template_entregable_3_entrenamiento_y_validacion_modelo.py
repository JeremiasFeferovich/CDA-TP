# -*- coding: utf-8 -*-
"""template_entregable_3_entrenamiento_y_validacion_modelo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1obfnUN9vHLPNcC6U_JmYhvHBTwBN7Af5

# Ciencia de datos aplicada (ITBA): Modelo de tercer entregable

**Entrenamiento y validaciÃ³n de Modelos de Machine Learning**

**Equipo:** Estudiante_1, Estudiante_2

**Nombre del proyecto**: Nombre definido para el proyecto en *Entregable 1*

## ğŸ§¾ Carga de datos y preparaciÃ³n

Usamos el clÃ¡sico dataset Iris, para lo cual preparamos los datos (en el caso de los equipos, los deberÃ­an cargar desde la etapa anterior de curado y pre-procesamiento):
"""

from sklearn.datasets import load_iris
import pandas as pd

iris = load_iris(as_frame=True)
df = iris.frame

X = df[iris.feature_names]
y = df['target']

""" Los separamos en entrenamiento y test:"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print('Train shape:', X_train.shape)
print('Test shape:', X_test.shape)

"""## ğŸ‹ï¸ Entrenamiento del Modelo

En este apartado, se entrenan y validan los modelos utilizando algÃºn mÃ©todo de validaciÃ³n, optimizaciÃ³n y bÃºsqueda de hiperparÃ¡metros (GridSearchCV).

En este modelo, se entrenan modelos a partir de dos tÃ©cnicas diferentes:
- Random Forest,
- MÃ¡quina Vector Soporte.

### ğŸ‹ï¸ Entrenamiento con Random Forest

En esta demostraciÃ³n, buscamos el mejor modelo de Random Forest, variando la cantidad de Ã¡rboles (`n_estimators`) y la profundidad mÃ¡xima (`max_depth`):
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 2, 4]
}

rf = RandomForestClassifier(random_state=42)
grid_rf = GridSearchCV(rf, param_grid_rf, cv=5)
grid_rf.fit(X_train, y_train)

print('Mejores hiperparÃ¡metros para Random Forest:', grid_rf.best_params_)
print('Accuracy en test:', grid_rf.score(X_test, y_test))

"""### ğŸ‹ï¸ Entrenamiento con SVM

Buscamos el mejor SVM cambiando el parÃ¡metro `C` y el tipo de kernel:
"""

from sklearn.svm import SVC

param_grid_svm = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf']
}

svm = SVC(probability=True, random_state=42)
grid_svm = GridSearchCV(svm, param_grid_svm, cv=5)
grid_svm.fit(X_train, y_train)

print('Mejores hiperparÃ¡metros para SVM:', grid_svm.best_params_)
print('Accuracy en test:', grid_svm.score(X_test, y_test))

"""## ğŸ” ComparaciÃ³n de resultados
Comparamos los resultados y elegimos el modelo con mayor accuracy en test.
"""

accuracy_rf = grid_rf.score(X_test, y_test)
accuracy_svm = grid_svm.score(X_test, y_test)

if accuracy_rf >= accuracy_svm:
    mejor_modelo = grid_rf.best_estimator_
    nombre_mejor = 'Random Forest'
else:
    mejor_modelo = grid_svm.best_estimator_
    nombre_mejor = 'SVM'

print(f'Modelo seleccionado: {nombre_mejor} (accuracy={max(accuracy_rf, accuracy_svm):.3f})')

"""### ğŸ“ MÃ©tricas y visualizaciÃ³n para el modelo seleccionado"""

from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

y_pred = mejor_modelo.predict(X_test)
print('Reporte de clasificaciÃ³n:')
print(classification_report(y_test, y_pred, target_names=iris.target_names))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.xlabel('Predicho')
plt.ylabel('Real')
plt.title(f'Matriz de ConfusiÃ³n â€” {nombre_mejor}')
plt.show()

"""### ğŸ‘©â€âš•ï¸AnÃ¡lisis de los resultados

AquÃ­ se analizan los resultados, tanto en tÃ©rminos de la eficacia de los modelos como del conocimiento que aportan.

## ğŸ’¾ Persistencia del modelo seleccionado

Guardamos el mejor modelo para usarlo luego en una nueva notebook.
"""

import joblib

joblib.dump(mejor_modelo, 'modelo_iris_mejor.joblib')
print('Modelo guardado como modelo_iris_mejor.joblib')

"""## ğŸ›« Cierre de la entrega: Reflexiones finales

En esta celda se hace un cierre de la etapa con observaciones sobre el resultado de los modelos, ventajas/desventajas, y posibles mejoras futuras.
"""